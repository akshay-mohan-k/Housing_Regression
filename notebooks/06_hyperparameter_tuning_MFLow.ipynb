{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cf7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.4\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260096cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Regression_ML_EndtoEnd\\.venv\\Scripts\\python.exe\n",
      "3.0.4\n",
      "e:\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys, xgboost as xgb\n",
    "print(sys.executable)        # should point to .../.venv/bin/python\n",
    "print(xgb.__version__)       # should print 3.0.4\n",
    "print(xgb.__file__)          # should live under .../.venv/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478bf394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 1. Imports\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bc804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (576815, 39)\n",
      "Eval shape: (148448, 39)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2. Load processed datasets\n",
    "# ==============================================\n",
    "train_df = pd.read_csv(\"E:/Regression_ML_EndtoEnd/data/processed/feature_engineered_train.csv\")\n",
    "eval_df  = pd.read_csv(\"E:/Regression_ML_EndtoEnd/data/processed/feature_engineered_eval.csv\")\n",
    "\n",
    "\n",
    "# Define target + features\n",
    "target = \"price\"\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_eval, y_eval   = eval_df.drop(columns=[target]), eval_df[target]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Eval shape:\", X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fadb78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 3. Define Optuna objective function with MLflow\n",
    "# ==============================================\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_eval)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_eval, y_pred)))\n",
    "        mae = float(mean_absolute_error(y_eval, y_pred))\n",
    "        r2 = float(r2_score(y_eval, y_pred))\n",
    "\n",
    "        # Log hyperparameters + metrics\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/11 17:06:21 INFO mlflow.tracking.fluent: Experiment with name 'xgboost_optuna_housing' does not exist. Creating a new experiment.\n",
      "[I 2025-12-11 17:06:21,460] A new study created in memory with name: no-name-4a0e0328-a1b7-4023-816c-27fb95320eb3\n",
      "[I 2025-12-11 17:06:40,557] Trial 0 finished with value: 73273.80963574036 and parameters: {'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.03581059712908792, 'subsample': 0.5716714033968613, 'colsample_bytree': 0.7880798583453523, 'min_child_weight': 9, 'gamma': 4.764838617821869, 'reg_alpha': 1.4884588257227434e-06, 'reg_lambda': 5.310533274858984e-05}. Best is trial 0 with value: 73273.80963574036.\n",
      "[I 2025-12-11 17:07:36,689] Trial 1 finished with value: 84701.26933580934 and parameters: {'n_estimators': 882, 'max_depth': 9, 'learning_rate': 0.1687129185893339, 'subsample': 0.9172625870157456, 'colsample_bytree': 0.7457767024144456, 'min_child_weight': 7, 'gamma': 4.003084427754876, 'reg_alpha': 2.344247116557514, 'reg_lambda': 3.1846921698988164e-06}. Best is trial 0 with value: 73273.80963574036.\n",
      "[I 2025-12-11 17:08:14,779] Trial 2 finished with value: 72159.28926803707 and parameters: {'n_estimators': 852, 'max_depth': 7, 'learning_rate': 0.029736920559848813, 'subsample': 0.5223698868465032, 'colsample_bytree': 0.9537350581543322, 'min_child_weight': 5, 'gamma': 3.7150765597474993, 'reg_alpha': 0.004524876533108551, 'reg_lambda': 2.5190516393896245e-07}. Best is trial 2 with value: 72159.28926803707.\n",
      "[I 2025-12-11 17:08:43,691] Trial 3 finished with value: 71465.48770310868 and parameters: {'n_estimators': 699, 'max_depth': 7, 'learning_rate': 0.030485672275429712, 'subsample': 0.7159258227283192, 'colsample_bytree': 0.7910880831589501, 'min_child_weight': 8, 'gamma': 0.03510099443433112, 'reg_alpha': 3.003304389901304e-07, 'reg_lambda': 6.27119637319553e-06}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:08:58,291] Trial 4 finished with value: 76941.33670139733 and parameters: {'n_estimators': 666, 'max_depth': 3, 'learning_rate': 0.12929099757951637, 'subsample': 0.9229875668075778, 'colsample_bytree': 0.5926090356275491, 'min_child_weight': 4, 'gamma': 1.9981221604439392, 'reg_alpha': 2.422852045603391, 'reg_lambda': 9.053030981465614e-05}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:09:26,828] Trial 5 finished with value: 82119.84950878513 and parameters: {'n_estimators': 890, 'max_depth': 6, 'learning_rate': 0.2958589239848317, 'subsample': 0.7237946429231842, 'colsample_bytree': 0.8205208034419804, 'min_child_weight': 9, 'gamma': 0.13073261863214003, 'reg_alpha': 1.8015182603989758e-08, 'reg_lambda': 0.5895309538255052}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:09:53,523] Trial 6 finished with value: 74938.91695621845 and parameters: {'n_estimators': 333, 'max_depth': 10, 'learning_rate': 0.04819094250834785, 'subsample': 0.9815542193631916, 'colsample_bytree': 0.5461219193902448, 'min_child_weight': 6, 'gamma': 0.03173875640041235, 'reg_alpha': 1.7313073530704553e-06, 'reg_lambda': 0.0013681851053695241}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:10:19,903] Trial 7 finished with value: 94695.7037255283 and parameters: {'n_estimators': 441, 'max_depth': 9, 'learning_rate': 0.24505781381450933, 'subsample': 0.9736171056006522, 'colsample_bytree': 0.8339365005142811, 'min_child_weight': 4, 'gamma': 1.0180420729495931, 'reg_alpha': 0.03239976020305387, 'reg_lambda': 0.00010863594053376863}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:10:52,549] Trial 8 finished with value: 80073.54398470839 and parameters: {'n_estimators': 864, 'max_depth': 7, 'learning_rate': 0.29200636326727963, 'subsample': 0.7038688429766691, 'colsample_bytree': 0.960902685924287, 'min_child_weight': 5, 'gamma': 0.0577304621966479, 'reg_alpha': 0.21852647275849435, 'reg_lambda': 6.306876648262733e-05}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:11:16,930] Trial 9 finished with value: 74220.79505585971 and parameters: {'n_estimators': 636, 'max_depth': 7, 'learning_rate': 0.08691476622421536, 'subsample': 0.6221055634557773, 'colsample_bytree': 0.7528500047798092, 'min_child_weight': 4, 'gamma': 4.017508896160588, 'reg_alpha': 1.9806482225228184, 'reg_lambda': 0.2038619225641416}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:11:25,134] Trial 10 finished with value: 99990.66080565905 and parameters: {'n_estimators': 265, 'max_depth': 4, 'learning_rate': 0.010636882878780427, 'subsample': 0.8091602786765503, 'colsample_bytree': 0.6308424378999468, 'min_child_weight': 1, 'gamma': 2.2057802093059866, 'reg_alpha': 2.9184631825625592e-05, 'reg_lambda': 1.5587969076795194e-08}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:12:02,315] Trial 11 finished with value: 73384.74106922951 and parameters: {'n_estimators': 783, 'max_depth': 8, 'learning_rate': 0.02235972350818558, 'subsample': 0.5085608765274912, 'colsample_bytree': 0.9968464565352876, 'min_child_weight': 7, 'gamma': 3.1050284969223876, 'reg_alpha': 0.001921911584278193, 'reg_lambda': 1.5470951794508104e-07}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:12:24,195] Trial 12 finished with value: 76974.58941136498 and parameters: {'n_estimators': 747, 'max_depth': 5, 'learning_rate': 0.02136825802408569, 'subsample': 0.7983962898458015, 'colsample_bytree': 0.9099792888094196, 'min_child_weight': 10, 'gamma': 3.121715935989851, 'reg_alpha': 0.0006409529069955882, 'reg_lambda': 8.257015847976775e-07}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:13:29,212] Trial 13 finished with value: 71842.88398049188 and parameters: {'n_estimators': 979, 'max_depth': 8, 'learning_rate': 0.02611507696394973, 'subsample': 0.6369393776822941, 'colsample_bytree': 0.897094111661652, 'min_child_weight': 2, 'gamma': 1.346338902550715, 'reg_alpha': 1.183982599165834e-08, 'reg_lambda': 0.010878858448170412}. Best is trial 3 with value: 71465.48770310868.\n",
      "[I 2025-12-11 17:14:20,236] Trial 14 finished with value: 70039.82129842295 and parameters: {'n_estimators': 993, 'max_depth': 8, 'learning_rate': 0.011979423656229036, 'subsample': 0.6472498837060974, 'colsample_bytree': 0.6800976378138136, 'min_child_weight': 1, 'gamma': 1.241004565506842, 'reg_alpha': 1.3940589734486386e-08, 'reg_lambda': 0.00801308343053586}. Best is trial 14 with value: 70039.82129842295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 993, 'max_depth': 8, 'learning_rate': 0.011979423656229036, 'subsample': 0.6472498837060974, 'colsample_bytree': 0.6800976378138136, 'min_child_weight': 1, 'gamma': 1.241004565506842, 'reg_alpha': 1.3940589734486386e-08, 'reg_lambda': 0.00801308343053586}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 4. Run Optuna study with MLflow\n",
    "# ==============================================\n",
    "# Force MLflow to always use the root project mlruns folder\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "mlflow.set_experiment(\"xgboost_optuna_housing\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b8c223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tuned model performance:\n",
      "MAE: 31524.516589745388\n",
      "RMSE: 69398.36193231442\n",
      "R²: 0.9627815339092367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [17:15:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/12/11 17:15:19 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/12/11 17:15:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 5. Train final model with best params and log to MLflow\n",
    "# ==============================================\n",
    "best_params = study.best_trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_eval)\n",
    "\n",
    "mae = mean_absolute_error(y_eval, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_eval, y_pred))\n",
    "r2 = r2_score(y_eval, y_pred)\n",
    "\n",
    "print(\"Final tuned model performance:\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Log final model\n",
    "with mlflow.start_run(run_name=\"best_xgboost_model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "    mlflow.xgboost.log_model(best_model, name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c1be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing-regression-mle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
